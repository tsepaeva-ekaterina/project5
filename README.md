Система поиска референсных изображений по текстовому описанию

Задача: Разработать прототип модели машинного обучения для поиска изображений, наиболее релевантных текстовому запросу. Модель оценивает степень соответствия текста и изображения по шкале от 0 до 1.

Цель: Создать демонстрационную версию для валидации гипотезы о возможности построения подобной системы для фотохостинга профессиональных фотографов.

Ключевые особенности
Мультимодальность: Модель одновременно анализирует текстовые запросы и изображения.
Контент-фильтр: Реализована система фильтрации запросов с нежелательной и потенциально опасной лексикой.
Интерпретируемость: В качестве базовых эмбеддингов используются хорошо изученные модели (TF-IDF для текста, ResNet50 для изображений), что упрощает анализ работы.
Качественные метрики: Оценка качества модели проводилась по метрикам регрессии: MSE, MAE, R².

Технологический стек
Язык программирования: Python 3
Библиотеки для ML: scikit-learn, TensorFlow/Keras, Pandas, NumPy
Обработка изображений: OpenCV, PIL
Векторизация текста: Scikit-learn (TfidfVectorizer)
Векторизация изображений: TensorFlow (предобученная ResNet50)
Визуализация: Matplotlib, Seaborn

Как это работает
Подготовка данных: Текстовые описания векторизуются с помощью TF-IDF. Изображения пропускаются через предобученную CNN (ResNet50) для получения векторных представлений.
Обучение модели: Вектора текста и изображения объединяются и подаются на вход регрессионной модели (линейная регрессия или нейронная сеть), которая обучается предсказывать экспертные оценки релевантности.
Поиск: Для нового текстового запроса система вычисляет его вектор, сравнивает (через скалярное произведение или с помощью обученной модели) с векторами всех изображений в базе и возвращает наиболее подходящие результаты.
